{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#dataset Extraction\n",
    "X= pd.read_csv(\"winequality-red.csv\")\n",
    "#data = np.array(X)\n",
    "data = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans Clustering took 0.49 s\n",
      "[3 3 3 ... 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "#Kmeans clustering considering default setting of algorithm\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "start_time = time.time()\n",
    "labels = kmeans.fit_predict(data)\n",
    "end_time = time.time()\n",
    "#plt.text(-0.5, 0.7, 'Clustering took {:.2f} s'.format(end_time - start_time), fontsize=14)\n",
    "print('Kmeans Clustering took {:.2f} s'.format(end_time - start_time))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 2\n",
      "Score: -15779.403293866368\n",
      "Silhoute Score:  0.20902052061684184\n",
      "Davies Bouldin Score:  1.9337663365008304\n",
      "Calinski Harabasz Score:  344.9768561154254\n",
      "BIC: 40863.30617231234\n",
      "Log likelihood: -12.360239202717135\n",
      "Cluster: 3\n",
      "Score: -14035.682857585454\n",
      "Silhoute Score:  0.17376473056446376\n",
      "Davies Bouldin Score:  1.8440534863636733\n",
      "Calinski Harabasz Score:  292.9354504063019\n",
      "BIC: 39433.09481616982\n",
      "Log likelihood: -11.703100202088487\n",
      "Cluster: 4\n",
      "Score: -12669.564263863413\n",
      "Silhoute Score:  0.18982521910911634\n",
      "Davies Bouldin Score:  1.5693105363257558\n",
      "Calinski Harabasz Score:  273.5401887180467\n",
      "BIC: 38959.18204705791\n",
      "Log likelihood: -11.344991403783359\n",
      "Cluster: 5\n",
      "Score: -11357.069312489897\n",
      "Silhoute Score:  0.1808384076304061\n",
      "Davies Bouldin Score:  1.495761285584281\n",
      "Calinski Harabasz Score:  274.7738693063077\n",
      "BIC: 38858.95932167827\n",
      "Log likelihood: -11.103733776126221\n",
      "Cluster: 6\n",
      "Score: -10569.50381548738\n",
      "Silhoute Score:  0.17921839331921238\n",
      "Davies Bouldin Score:  1.4420508076193095\n",
      "Calinski Harabasz Score:  259.7921204377935\n",
      "BIC: 38958.199750361106\n",
      "Log likelihood: -10.924847366124641\n",
      "Cluster: 7\n",
      "Score: -9823.921623897322\n",
      "Silhoute Score:  0.17580332537531435\n",
      "Davies Bouldin Score:  1.5095071266684619\n",
      "Calinski Harabasz Score:  252.91347226162262\n",
      "BIC: 38890.70634586503\n",
      "Log likelihood: -10.693824047686878\n",
      "Cluster: 8\n",
      "Score: -9458.542738497857\n",
      "Silhoute Score:  0.16884936663236008\n",
      "Davies Bouldin Score:  1.5488887527544553\n",
      "Calinski Harabasz Score:  233.7957024069057\n",
      "BIC: 27526.78820693913\n",
      "Log likelihood: -6.930460286963366\n",
      "Cluster: 9\n",
      "Score: -9083.59935048823\n",
      "Silhoute Score:  0.14428839055564943\n",
      "Davies Bouldin Score:  1.6215779609748582\n",
      "Calinski Harabasz Score:  221.08522751859647\n",
      "BIC: 39113.41629562568\n",
      "Log likelihood: -10.343627554261259\n",
      "Cluster: 10\n",
      "Score: -8806.438743927514\n",
      "Silhoute Score:  0.13812440880961044\n",
      "Davies Bouldin Score:  1.637793456862496\n",
      "Calinski Harabasz Score:  208.13433992983846\n",
      "BIC: 28288.14954312717\n",
      "Log likelihood: -6.748697622939683\n",
      "Cluster: 11\n",
      "Score: -8552.016928615183\n",
      "Silhoute Score:  0.14953707403844688\n",
      "Davies Bouldin Score:  1.6185243187704033\n",
      "Calinski Harabasz Score:  197.49658189806755\n",
      "BIC: 28505.932562940125\n",
      "Log likelihood: -6.606878939995675\n",
      "[-15779.403293866368, -14035.682857585454, -12669.564263863413, -11357.069312489897, -10569.50381548738, -9823.921623897322, -9458.542738497857, -9083.59935048823, -8806.438743927514, -8552.016928615183]\n"
     ]
    }
   ],
   "source": [
    "#Evaluattion\n",
    "from sklearn.metrics import *\n",
    "from sklearn.mixture import GaussianMixture\n",
    "km=[]\n",
    "sil=[]\n",
    "db=[]\n",
    "ch=[]\n",
    "gm=[]\n",
    "gm_bic=[]\n",
    "for i in range(2,12):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    start_time = time.time()\n",
    "    labels = kmeans.fit_predict(data)\n",
    "    end_time = time.time()\n",
    "    print(\"Cluster:\",i)\n",
    "    km.append(kmeans.score(data))\n",
    "    print(\"Score:\",kmeans.score(data))\n",
    "    sil_score = silhouette_score(data,labels)\n",
    "    dav_score = davies_bouldin_score(data, labels)\n",
    "    cal_score = calinski_harabasz_score(data, labels)\n",
    "    gaussian_mix=GaussianMixture(n_components=i,n_init=10,tol=1e-3,max_iter=1000).fit(data)\n",
    "    sil.append(sil_score)\n",
    "    db.append(dav_score)\n",
    "    ch.append(cal_score)\n",
    "    gm.append(gaussian_mix.score(data))\n",
    "    gm_bic.append(gaussian_mix.bic(data))\n",
    "    print('Silhoute Score: ',sil_score)\n",
    "    print('Davies Bouldin Score: ',dav_score)\n",
    "    print('Calinski Harabasz Score: ',cal_score)\n",
    "    print('BIC:',gaussian_mix.bic(data))\n",
    "    print('Log likelihood:',gaussian_mix.score(data))\n",
    "\n",
    "print(km)\n",
    "#cluster.contingency_matrix(data,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= pd.read_csv(\"winequality-red.csv\")\n",
    "#data = np.array(X)\n",
    "data = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "af_model=AffinityPropagation(preference=-70).fit(data)\n",
    "cluster_centers_indices = af_model.cluster_centers_indices_\n",
    "labels = af_model.labels_\n",
    "n_clusters=len(cluster_centers_indices)\n",
    "\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
